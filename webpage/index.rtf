{\rtf1\ansi\deff0{\fonttbl{\f0 \fswiss Helvetica;}{\f1 Courier;}}
{\colortbl;\red255\green0\blue0;\red0\green0\blue255;}
\widowctrl\hyphauto

{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 CS583: Deep Learning\par}
{\pard \ql \f0 \sa180 \li720 \fi0 Instructor: Shusen Wang\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Read this before taking the course!\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The course requires very heavy workload (in fact much heavier than the previous semester). {\b Do NOT take this course unless you can spend much time on this course.}\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab You are required (instead of \u8220"recommended\u8221") to read the text book, \u8220"Deep learning with Python\u8221", and run the example code. In the quizzes and final exam, there will be questions based on the book\u8217's content, especially the content not covered in the class.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab You are required to participate a Kaggle competition and get a decent score and ranking.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab There are at least 5 homework.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab There are additional programming assignment, by doing which you will receive bonus score. Get \u8220"A\u8221" is difficult without collecting the bonus.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Be serious about the prerequisites. Do NOT take the course if you do not meet the prerequisite requirements.}\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab In the 2nd class, you will be asked to do a quiz (weight in the grading: around 5%). The quiz will test your knowledge in elementary algebra and calculus and Python programming (especially NumPy).\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab There will be a quiz on matrix algebra, matrix calculus, and optimization.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab In the final exam, there will be questions on matrix algebra, differentiation, optimization, and Python code understanding.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Before the class begins, get yourself well prepared by:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Reading a few chapters of the textbook, {\i \u8220"Deep learning with Python\u8221"}, and running the sample code.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Doing Homework 0: [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/HM0/HM.pdf"}}{\fldrslt{\ul
click here
}}}
].\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Description\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Meeting Time:}\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Thursday, 6:30-9:00 PM, classroom TBD\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Office Hours:}\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Thursday, 3:00 - 5:00 PM, North Building 205\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Contact the Instructor:}\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab For questions regarding grading, talk to the instructor during office hours or send him emails.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab For any other questions, come during the office hours; the instructor will NOT reply such emails.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Prerequisite:}\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Elementary linear algebra, e.g., matrix multiplication, eigenvalue decomposition, and matrix norms.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Elementary calculus, e.g., convex function, differentiation of scalar functions, first derivative, and second derivative.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Python programming (especially the Numpy library) and Jupyter Notebook.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Goal:} This is a practical course; the students will be able to use DL methods for solving real-world ML, CV, and NLP problems. The students will also learn math and theories for understanding ML and DL.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Schedule\par}
{\pard \ql \f0 \sa180 \li0 \fi0 TBD\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Syllabus and Slides\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 1.\tx360\tab {\b Machine learning basics.} This part briefly introduces the fundamental ML problems\u8211- regression, classification, dimensionality reduction, and clustering\u8211- and the traditional ML models and numerical algorithms for solving the problems.\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab ML basics. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/1_ML_Basics.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Regression. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/2_Regression_1.pdf"}}{\fldrslt{\ul
slides-1
}}}
] [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/2_Regression_2.pdf"}}{\fldrslt{\ul
slides-2
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Classification. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/3_Classification_1.pdf"}}{\fldrslt{\ul
slides-1
}}}
][{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/3_Classification_2.pdf"}}{\fldrslt{\ul
slides-2
}}}
] [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/3_Classification_3.pdf"}}{\fldrslt{\ul
slides-3
}}}
] [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/3_Classification_4.pdf"}}{\fldrslt{\ul
slides-4
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Regularizations. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/3_Optimization.pdf"}}{\fldrslt{\ul
slides-1
}}}
][{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/3_Regularizations.pdf"}}{\fldrslt{\ul
slides-2
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Clustering. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/4_Clustering.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Dimensionality reduction. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/5_DR_1.pdf"}}{\fldrslt{\ul
slides-1
}}}
] [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/5_DR_2.pdf"}}{\fldrslt{\ul
slides-2
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Scientific computing libraries. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/5_DR_3.pdf"}}{\fldrslt{\ul
slides
}}}
]\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 2.\tx360\tab {\b Neural network basics.} This part covers the multilayer perceptron, backpropagation, and deep learning libraries, with focus on Keras.\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Multilayer perceptron and backpropagation. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/6_NeuralNet_1.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Keras. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/6_NeuralNet_2.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Further reading: [{\field{\*\fldinst{HYPERLINK "https://adl1995.github.io/an-overview-of-activation-functions-used-in-neural-networks.html"}}{\fldrslt{\ul
activation functions
}}}
][{\field{\*\fldinst{HYPERLINK "https://isaacchanghau.github.io/post/loss_functions/"}}{\fldrslt{\ul
loss functions
}}}
] [{\field{\*\fldinst{HYPERLINK "https://isaacchanghau.github.io/post/weight_initialization/"}}{\fldrslt{\ul
parameter initialization
}}}
][{\field{\*\fldinst{HYPERLINK "https://isaacchanghau.github.io/post/parameters_update/"}}{\fldrslt{\ul
optimization algorithms
}}}
]\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 3.\tx360\tab {\b Convolutional neural networks (CNNs).} This part is focused on CNNs and its application to computer vision problems.\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab CNN basics. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/7_CNN_1.pdf"}}{\fldrslt{\ul
slides-1
}}}
][{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/7_CNN_2.pdf"}}{\fldrslt{\ul
slides-2
}}}
] [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/7_CNN_3.pdf"}}{\fldrslt{\ul
slides-3
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Advanced topics on CNNs. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/7_CNN_4.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Popular CNN architectures. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/7_CNN_5.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Face recognition. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/7_CNN_6.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Further reading:\par}
{\pard \ql \f0 \sa180 \li1080 \fi-360 \bullet \tx360\tab [style transfer (Section 8.1, Chollet\u8217's book)]\par}
{\pard \ql \f0 \sa180 \li1080 \fi-360 \bullet \tx360\tab [visualize CNN (Section 5.4, Chollet\u8217's book)]\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 4.\tx360\tab {\b Autoencoders.} This part introduces autoencoders for dimensionality reduction and image generation.\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Autoencoder for dimensionality reduction. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/8_AE_1.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Variational Autoencoders (VAEs) for image generation. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/8_AE_2.pdf"}}{\fldrslt{\ul
slides
}}}
]\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 5.\tx360\tab {\b Recurrent neural networks (RNNs).} This part introduces RNNs and its applications in natural language processing (NLP).\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Text processing. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/9_RNN_1.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab RNN basics and LSTM. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/9_RNN_2.pdf"}}{\fldrslt{\ul
slides
}}}
][{\field{\*\fldinst{HYPERLINK "http://colah.github.io/posts/2015-08-Understanding-LSTMs/"}}{\fldrslt{\ul
reference
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Text generation. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/9_RNN_3.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Machine translation. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/9_RNN_4.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Attention. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/9_RNN_5.pdf"}}{\fldrslt{\ul
slides
}}}
][{\field{\*\fldinst{HYPERLINK "https://distill.pub/2016/augmented-rnns/"}}{\fldrslt{\ul
reference-1
}}}
] [{\field{\*\fldinst{HYPERLINK "https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html"}}{\fldrslt{\ul
reference-2
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Image caption generation. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/9_RNN_6.pdf"}}{\fldrslt{\ul
slides
}}}
][{\field{\*\fldinst{HYPERLINK "https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/"}}{\fldrslt{\ul
reference
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Transformer model: beyond RNNs. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/9_RNN_7.pdf"}}{\fldrslt{\ul
slides
}}}
][{\field{\*\fldinst{HYPERLINK "https://arxiv.org/pdf/1706.03762.pdf"}}{\fldrslt{\ul
reference
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Further reading:\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab [{\field{\*\fldinst{HYPERLINK "http://www.aclweb.org/anthology/D14-1162"}}{\fldrslt{\ul
GloVe: Global Vectors for Word Representation
}}}
]\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab [{\field{\*\fldinst{HYPERLINK "https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf"}}{\fldrslt{\ul
Neural Word Embedding as Implicit Matrix Factorization
}}}
]\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 6.\tx360\tab {\b Recommender system.} This part is focused on the collaborative filtering approach to recommendation based on the user-item rating data. This part covers matrix completion methods and neural network approaches.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Collaborative filtering. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/10_Recommender.pdf"}}{\fldrslt{\ul
slides
}}}
]\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 7.\tx360\tab {\b Adversarial Robustness.} This part introduces how to attack neural networks using adversarial examples and how to defend from the attack.\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab White box attack and defend. [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/slides/11_Adversarial.pdf"}}{\fldrslt{\ul
slides
}}}
]\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Further reading: [{\field{\*\fldinst{HYPERLINK "https://adversarial-ml-tutorial.org/"}}{\fldrslt{\ul
Adversarial Robustness - Theory and Practice
}}}
]\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 8.\tx360\tab {\b Generative Adversarial Networks (GANs).} {\b (Optional, depending on the progress.)}\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Project\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Every student must participate in one {\field{\*\fldinst{HYPERLINK "https://www.kaggle.com/competitions"}}{\fldrslt{\ul
Kaggle competition
}}}
.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab {\b Details}: [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/project/Project/proj.pdf"}}{\fldrslt{\ul
click here
}}}
]\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab {\b Teamwork policy}: You had better work on your own project. Teamwork (up to 3 students) is allowed if the competition has a heavy workload; the workload and team size will be considered in the grading.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab {\b Grading policy}: see the tentative evaluation form [{\field{\*\fldinst{HYPERLINK "https://github.com/wangshusen/CS583A-2019Spring/blob/master/project/Evaluation/Evaluation.pdf"}}{\fldrslt{\ul
click here
}}}
]\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Textbooks\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Required} (Please notice the difference between \u8220"required\u8221" and \u8220"recommended\u8221"):\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Francois Chollet. Deep learning with Python. Manning Publications Co., 2017. (Available online.)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Recommended}:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Y. Nesterov. Introductory Lectures on Convex Optimization Book. Springer, 2013. (Available online.)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab D. S. Watkins. Fundamentals of Matrix Computations. John Wiley & Sons, 2004.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab I. Goodfellow, Y. Bengio, A. Courville, Y. Bengio. Deep learning. MIT press, 2016. (Available online.)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab M. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundations of machine learning. MIT press, 2012.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab J. Friedman, T. Hastie, and R. Tibshirani. The elements of statistical learning. Springer series in statistics, 2001. (Available online.)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Grading Policy\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Grading percentages}:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Homework 45%\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Final 15%\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Project 20%\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Quizzes 20%\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Bonus (up to 10%)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 {\b Late penalty}:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Late submissions of assignments or project document for whatever reason will be punished. 1% of the score of an assignment/project will be deducted per day. For example, if an assignment is submitted 15 days and 1 minute later than the deadline (counted as 16 days) and it gets a grade of 95%, then the score after the deduction will be: 95% - 16% = 79%.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Dec 20 is the firm deadline for all the homework and the course project. Submissions later than the firm deadline will not be graded.\sa180\par}
}
